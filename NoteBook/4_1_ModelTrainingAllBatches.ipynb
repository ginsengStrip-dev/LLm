{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96c63b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fafb7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minbpe import BasicTokenizer\n",
    "\n",
    "tokenizer = BasicTokenizer()\n",
    "tokenizer.load(model_file=\"../Data/tokenizer/my_tokenizer.model\")\n",
    "\n",
    "\n",
    "def get_vocab_size(tokenizer: BasicTokenizer) -> int:\n",
    "    vocab = tokenizer.vocab\n",
    "    special_tokens = tokenizer.special_tokens\n",
    "\n",
    "    return len(vocab) + len(special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c04fc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x14037adf6d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(3647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "786fec5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.342794 M parameters\n"
     ]
    }
   ],
   "source": [
    "from transformer.model import GPTLanguageModel\n",
    "\n",
    "block_size = 256\n",
    "n_embd =512\n",
    "n_head = 4\n",
    "n_layer = 1\n",
    "dropout = 0.2\n",
    "batch_size = 32\n",
    "vocab_size = get_vocab_size(tokenizer)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = GPTLanguageModel(\n",
    "    vocab_size=vocab_size,\n",
    "    block_size=block_size,\n",
    "    n_embd=n_embd,\n",
    "    n_head=n_head,\n",
    "    n_layer=n_layer,\n",
    "    dropout=dropout,\n",
    "    device=device\n",
    ").to(device)\n",
    "model = torch.compile(model)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72a02bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffc29ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu128\n",
      "12.8\n",
      "90701\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fb7c04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1760"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# load npy instead of txt\n",
    "recipes = np.load(\"recipes_cleaned.npy\", allow_pickle=True)\n",
    "text_sequence = \"\\n\".join(recipes)\n",
    "\n",
    "encoded_text_sequence = tokenizer.encode(text_sequence)\n",
    "len(encoded_text_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87392371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../Data/combined_text.txt\", \"r\") as f:\n",
    "#     text_sequence = f.read()\n",
    "\n",
    "# encoded_text_sequence = tokenizer.encode(text_sequence)\n",
    "# len(encoded_text_sequence)\n",
    "# with open(\"../Data/combined_text.txt\", \"r\", encoding='utf-8') as f:\n",
    "#     text_sequence = f.read()\n",
    "\n",
    "# encoded_text_sequence = tokenizer.encode(text_sequence)\n",
    "# len(encoded_text_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9da7e816",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encoded_text_sequence, dtype=torch.long)\n",
    "split_index = int(0.5*len(data))\n",
    "train_data = data[:split_index]\n",
    "val_data = data[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66fca2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data: torch.Tensor, block_size: int) -> None:\n",
    "        self.data = data\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data) - self.block_size\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        x = self.data[index:index + self.block_size]\n",
    "        y = self.data[index + 1:index + self.block_size + 1]\n",
    "        return x, y\n",
    "\n",
    "\n",
    "def get_dataloaders(\n",
    "        train_data: torch.Tensor,\n",
    "        val_data: torch.Tensor,\n",
    "        block_size: int,\n",
    "        batch_size: int,\n",
    "        device: torch.device\n",
    ") -> Tuple[DataLoader, DataLoader]:\n",
    "    train_dataset = TextDataset(train_data.to(device), block_size)\n",
    "    val_dataset = TextDataset(val_data.to(device), block_size)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "443320e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 256]), torch.Size([32, 256]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, val_loader = get_dataloaders(\n",
    "    train_data=train_data,\n",
    "    val_data=val_data,\n",
    "    block_size=block_size,\n",
    "    batch_size=batch_size,\n",
    "    device=device\n",
    ")\n",
    "x, y = next(iter(train_loader))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45c848de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(\n",
    "    model: torch.nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    eval_iters: int\n",
    ") -> Dict[str, float]:\n",
    "    output = {}\n",
    "    model.eval()\n",
    "\n",
    "    for split, loader in [('train', train_loader), ('val', val_loader)]:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for i, (x, y) in enumerate(loader):\n",
    "            if i >= eval_iters:\n",
    "                break\n",
    "            with torch.no_grad():\n",
    "                _, loss = model(x, y)\n",
    "            losses[i] = loss.item()\n",
    "        output[split] = losses.mean().item()\n",
    "\n",
    "    model.train()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99e0fa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(\n",
    "    model: GPTLanguageModel,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epoch: int,\n",
    "    loss: float,\n",
    "    file_path: str = \"checkpoint.pth\"\n",
    ") -> None:\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "    }\n",
    "    torch.save(checkpoint, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f332e866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "# --- Disable Triton checks ---\n",
    "os.environ[\"TORCHINDUCTOR_DISABLE_TRITON\"] = \"1\"\n",
    "\n",
    "# --- Suppress TorchDynamo / Inductor warnings ---\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Optional: fully disable TorchDynamo verbose logging\n",
    "import torch._dynamo as dynamo\n",
    "dynamo.reset()\n",
    "dynamo.config.verbose = 0\n",
    "dynamo.config.suppress_errors = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b6d4b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "880\n",
      "880\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data), type(val_data))\n",
    "print(len(train_data))\n",
    "print(len(val_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb4d5890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880 880\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(val_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65cd08f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0903 20:35:55.705629 9792 site-packages\\torch\\_inductor\\utils.py:1250] [0/0] Not enough SMs to use max_autotune_gemm mode\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] WON'T CONVERT forward d:\\WORK space\\LLm\\NoteBook\\..\\transformer\\model.py line 129 \n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] due to: \n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Traceback (most recent call last):\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1213, in __call__\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     result = self._inner_convert(\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 598, in __call__\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile(\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1059, in _compile\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils_internal.py\", line 97, in wrapper_function\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return function(*args, **kwargs)\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 761, in compile_inner\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in _compile_inner\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     out_code = transform_code_object(code, transform)\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1422, in transform_code_object\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     transformations(instructions, code_options)\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 257, in _fn\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return fn(*args, **kwargs)\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in transform\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     tracer.run()\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3498, in run\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     super().run()\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1337, in run\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     while self.step():\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1246, in step\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3699, in RETURN_VALUE\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self._return(inst)\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3684, in _return\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.output.compile_subgraph(\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1179, in compile_subgraph\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.compile_and_call_fx_graph(\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1437, in compile_and_call_fx_graph\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1487, in call_user_compiler\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return self._call_user_compiler(gm)\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1519, in _call_user_compiler\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 150, in __call__\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py\", line 2347, in __call__\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 2100, in compile_fx\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3957, in create_backend\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise TritonMissing(inspect.currentframe())\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] torch._inductor.exc.TritonMissing: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Traceback (most recent call last):\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1213, in __call__\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     result = self._inner_convert(\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 598, in __call__\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile(\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1059, in _compile\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils_internal.py\", line 97, in wrapper_function\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return function(*args, **kwargs)\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 761, in compile_inner\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in _compile_inner\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     out_code = transform_code_object(code, transform)\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1422, in transform_code_object\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     transformations(instructions, code_options)\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 257, in _fn\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return fn(*args, **kwargs)\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in transform\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     tracer.run()\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3498, in run\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     super().run()\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1337, in run\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     while self.step():\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1246, in step\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3699, in RETURN_VALUE\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self._return(inst)\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3684, in _return\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.output.compile_subgraph(\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1179, in compile_subgraph\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.compile_and_call_fx_graph(\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1437, in compile_and_call_fx_graph\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1487, in call_user_compiler\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return self._call_user_compiler(gm)\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1519, in _call_user_compiler\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 150, in __call__\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py\", line 2347, in __call__\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 2100, in compile_fx\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3957, in create_backend\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise TritonMissing(inspect.currentframe())\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] torch._inductor.exc.TritonMissing: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "W0903 20:35:56.057777 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] WON'T CONVERT forward d:\\WORK space\\LLm\\NoteBook\\..\\transformer\\model.py line 86 \n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] due to: \n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Traceback (most recent call last):\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1213, in __call__\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     result = self._inner_convert(\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 598, in __call__\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile(\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1059, in _compile\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils_internal.py\", line 97, in wrapper_function\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return function(*args, **kwargs)\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 761, in compile_inner\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in _compile_inner\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     out_code = transform_code_object(code, transform)\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1422, in transform_code_object\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     transformations(instructions, code_options)\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 257, in _fn\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return fn(*args, **kwargs)\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in transform\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     tracer.run()\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3498, in run\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     super().run()\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1337, in run\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     while self.step():\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1246, in step\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3699, in RETURN_VALUE\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self._return(inst)\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3684, in _return\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.output.compile_subgraph(\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1144, in compile_subgraph\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.compile_and_call_fx_graph(\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1437, in compile_and_call_fx_graph\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1487, in call_user_compiler\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return self._call_user_compiler(gm)\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1519, in _call_user_compiler\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 150, in __call__\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py\", line 2347, in __call__\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 2100, in compile_fx\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3957, in create_backend\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise TritonMissing(inspect.currentframe())\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] torch._inductor.exc.TritonMissing: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Traceback (most recent call last):\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1213, in __call__\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     result = self._inner_convert(\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 598, in __call__\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile(\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1059, in _compile\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils_internal.py\", line 97, in wrapper_function\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return function(*args, **kwargs)\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 761, in compile_inner\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in _compile_inner\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     out_code = transform_code_object(code, transform)\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1422, in transform_code_object\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     transformations(instructions, code_options)\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 257, in _fn\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return fn(*args, **kwargs)\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in transform\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     tracer.run()\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3498, in run\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     super().run()\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1337, in run\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     while self.step():\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1246, in step\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3699, in RETURN_VALUE\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self._return(inst)\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3684, in _return\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.output.compile_subgraph(\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1144, in compile_subgraph\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.compile_and_call_fx_graph(\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1437, in compile_and_call_fx_graph\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1487, in call_user_compiler\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return self._call_user_compiler(gm)\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1519, in _call_user_compiler\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 150, in __call__\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py\", line 2347, in __call__\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 2100, in compile_fx\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3957, in create_backend\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise TritonMissing(inspect.currentframe())\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] torch._inductor.exc.TritonMissing: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "W0903 20:35:57.648265 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] WON'T CONVERT forward d:\\WORK space\\LLm\\NoteBook\\..\\transformer\\model.py line 45 \n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] due to: \n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Traceback (most recent call last):\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1213, in __call__\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     result = self._inner_convert(\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 598, in __call__\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile(\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1059, in _compile\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils_internal.py\", line 97, in wrapper_function\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return function(*args, **kwargs)\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 761, in compile_inner\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in _compile_inner\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     out_code = transform_code_object(code, transform)\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1422, in transform_code_object\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     transformations(instructions, code_options)\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 257, in _fn\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return fn(*args, **kwargs)\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in transform\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     tracer.run()\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3498, in run\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     super().run()\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1337, in run\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     while self.step():\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1246, in step\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3699, in RETURN_VALUE\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self._return(inst)\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3684, in _return\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.output.compile_subgraph(\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1144, in compile_subgraph\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.compile_and_call_fx_graph(\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1437, in compile_and_call_fx_graph\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1487, in call_user_compiler\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return self._call_user_compiler(gm)\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1519, in _call_user_compiler\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 150, in __call__\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py\", line 2347, in __call__\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 2100, in compile_fx\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3957, in create_backend\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise TritonMissing(inspect.currentframe())\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] torch._inductor.exc.TritonMissing: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Traceback (most recent call last):\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1213, in __call__\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     result = self._inner_convert(\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 598, in __call__\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile(\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1059, in _compile\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils_internal.py\", line 97, in wrapper_function\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return function(*args, **kwargs)\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 761, in compile_inner\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in _compile_inner\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     out_code = transform_code_object(code, transform)\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1422, in transform_code_object\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     transformations(instructions, code_options)\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 257, in _fn\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return fn(*args, **kwargs)\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in transform\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     tracer.run()\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3498, in run\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     super().run()\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1337, in run\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     while self.step():\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1246, in step\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3699, in RETURN_VALUE\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self._return(inst)\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3684, in _return\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.output.compile_subgraph(\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1144, in compile_subgraph\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.compile_and_call_fx_graph(\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1437, in compile_and_call_fx_graph\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1487, in call_user_compiler\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return self._call_user_compiler(gm)\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1519, in _call_user_compiler\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 150, in __call__\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py\", line 2347, in __call__\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 2100, in compile_fx\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3957, in create_backend\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise TritonMissing(inspect.currentframe())\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] torch._inductor.exc.TritonMissing: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "W0903 20:35:58.925416 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] WON'T CONVERT forward d:\\WORK space\\LLm\\NoteBook\\..\\transformer\\model.py line 20 \n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] due to: \n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Traceback (most recent call last):\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1213, in __call__\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     result = self._inner_convert(\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 598, in __call__\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile(\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1059, in _compile\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils_internal.py\", line 97, in wrapper_function\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return function(*args, **kwargs)\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 761, in compile_inner\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in _compile_inner\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     out_code = transform_code_object(code, transform)\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1422, in transform_code_object\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     transformations(instructions, code_options)\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 257, in _fn\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return fn(*args, **kwargs)\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in transform\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     tracer.run()\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3498, in run\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     super().run()\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1337, in run\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     while self.step():\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1246, in step\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3699, in RETURN_VALUE\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self._return(inst)\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3684, in _return\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.output.compile_subgraph(\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1144, in compile_subgraph\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.compile_and_call_fx_graph(\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1437, in compile_and_call_fx_graph\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1487, in call_user_compiler\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return self._call_user_compiler(gm)\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1519, in _call_user_compiler\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 150, in __call__\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py\", line 2347, in __call__\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 2100, in compile_fx\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3957, in create_backend\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise TritonMissing(inspect.currentframe())\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] torch._inductor.exc.TritonMissing: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Traceback (most recent call last):\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1213, in __call__\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     result = self._inner_convert(\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 598, in __call__\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile(\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1059, in _compile\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils_internal.py\", line 97, in wrapper_function\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return function(*args, **kwargs)\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 761, in compile_inner\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in _compile_inner\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     out_code = transform_code_object(code, transform)\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1422, in transform_code_object\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     transformations(instructions, code_options)\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 257, in _fn\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return fn(*args, **kwargs)\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in transform\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     tracer.run()\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3498, in run\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     super().run()\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1337, in run\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     while self.step():\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1246, in step\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3699, in RETURN_VALUE\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self._return(inst)\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3684, in _return\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.output.compile_subgraph(\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1144, in compile_subgraph\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.compile_and_call_fx_graph(\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1437, in compile_and_call_fx_graph\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1487, in call_user_compiler\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return self._call_user_compiler(gm)\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1519, in _call_user_compiler\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 150, in __call__\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py\", line 2347, in __call__\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 2100, in compile_fx\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3957, in create_backend\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise TritonMissing(inspect.currentframe())\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] torch._inductor.exc.TritonMissing: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "W0903 20:35:59.291537 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] WON'T CONVERT forward d:\\WORK space\\LLm\\NoteBook\\..\\transformer\\model.py line 63 \n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] due to: \n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Traceback (most recent call last):\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1213, in __call__\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     result = self._inner_convert(\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 598, in __call__\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile(\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1059, in _compile\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils_internal.py\", line 97, in wrapper_function\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return function(*args, **kwargs)\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 761, in compile_inner\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in _compile_inner\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     out_code = transform_code_object(code, transform)\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1422, in transform_code_object\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     transformations(instructions, code_options)\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 257, in _fn\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return fn(*args, **kwargs)\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in transform\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     tracer.run()\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3498, in run\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     super().run()\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1337, in run\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     while self.step():\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1246, in step\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3699, in RETURN_VALUE\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self._return(inst)\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3684, in _return\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.output.compile_subgraph(\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1144, in compile_subgraph\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.compile_and_call_fx_graph(\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1437, in compile_and_call_fx_graph\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1487, in call_user_compiler\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return self._call_user_compiler(gm)\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1519, in _call_user_compiler\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 150, in __call__\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py\", line 2347, in __call__\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 2100, in compile_fx\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3957, in create_backend\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise TritonMissing(inspect.currentframe())\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] torch._inductor.exc.TritonMissing: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Traceback (most recent call last):\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1213, in __call__\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     result = self._inner_convert(\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 598, in __call__\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile(\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1059, in _compile\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils_internal.py\", line 97, in wrapper_function\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return function(*args, **kwargs)\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 761, in compile_inner\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in _compile_inner\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     out_code = transform_code_object(code, transform)\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1422, in transform_code_object\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     transformations(instructions, code_options)\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 257, in _fn\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return fn(*args, **kwargs)\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in transform\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     tracer.run()\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3498, in run\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     super().run()\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1337, in run\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     while self.step():\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1246, in step\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3699, in RETURN_VALUE\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self._return(inst)\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3684, in _return\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.output.compile_subgraph(\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1144, in compile_subgraph\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.compile_and_call_fx_graph(\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1437, in compile_and_call_fx_graph\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1487, in call_user_compiler\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return self._call_user_compiler(gm)\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1519, in _call_user_compiler\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 150, in __call__\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py\", line 2347, in __call__\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 2100, in compile_fx\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3957, in create_backend\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise TritonMissing(inspect.currentframe())\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] torch._inductor.exc.TritonMissing: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "W0903 20:35:59.597161 9792 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / step 0: train loss 7.0614, val loss 7.0625\n",
      "iteration 0 / step 19: train loss 5.1625, val loss 6.8327\n",
      "iteration 1 / step 0: train loss 5.0589, val loss 6.8351\n",
      "iteration 1 / step 19: train loss 3.3115, val loss 6.8940\n",
      "iteration 2 / step 0: train loss 3.2117, val loss 6.8980\n",
      "iteration 2 / step 19: train loss 1.8665, val loss 7.0578\n",
      "iteration 3 / step 0: train loss 1.8008, val loss 7.0715\n",
      "iteration 3 / step 19: train loss 1.0828, val loss 7.3667\n",
      "iteration 4 / step 0: train loss 1.0598, val loss 7.3811\n",
      "iteration 4 / step 19: train loss 0.7338, val loss 7.6708\n",
      "iteration 5 / step 0: train loss 0.6870, val loss 7.6828\n",
      "iteration 5 / step 19: train loss 0.4665, val loss 7.9184\n",
      "iteration 6 / step 0: train loss 0.4679, val loss 7.9271\n",
      "iteration 6 / step 19: train loss 0.3306, val loss 8.1142\n",
      "iteration 7 / step 0: train loss 0.3120, val loss 8.1209\n",
      "iteration 7 / step 19: train loss 0.2316, val loss 8.2705\n",
      "iteration 8 / step 0: train loss 0.2256, val loss 8.2798\n",
      "iteration 8 / step 19: train loss 0.1611, val loss 8.4026\n",
      "iteration 9 / step 0: train loss 0.1706, val loss 8.4102\n",
      "iteration 9 / step 19: train loss 0.1192, val loss 8.5135\n",
      "iteration 10 / step 0: train loss 0.1183, val loss 8.5223\n",
      "iteration 10 / step 19: train loss 0.0902, val loss 8.6145\n",
      "iteration 11 / step 0: train loss 0.0817, val loss 8.6170\n",
      "iteration 11 / step 19: train loss 0.0583, val loss 8.7081\n",
      "iteration 12 / step 0: train loss 0.0606, val loss 8.7106\n",
      "iteration 12 / step 19: train loss 0.0449, val loss 8.7831\n",
      "iteration 13 / step 0: train loss 0.0422, val loss 8.7887\n",
      "iteration 13 / step 19: train loss 0.0320, val loss 8.8601\n",
      "iteration 14 / step 0: train loss 0.0316, val loss 8.8626\n",
      "iteration 14 / step 19: train loss 0.0268, val loss 8.9245\n",
      "iteration 15 / step 0: train loss 0.0271, val loss 8.9291\n",
      "iteration 15 / step 19: train loss 0.0203, val loss 8.9975\n",
      "iteration 16 / step 0: train loss 0.0204, val loss 8.9977\n",
      "iteration 16 / step 19: train loss 0.0182, val loss 9.0562\n",
      "iteration 17 / step 0: train loss 0.0179, val loss 9.0577\n",
      "iteration 17 / step 19: train loss 0.0153, val loss 9.1013\n",
      "iteration 18 / step 0: train loss 0.0152, val loss 9.1034\n",
      "iteration 18 / step 19: train loss 0.0131, val loss 9.1439\n",
      "iteration 19 / step 0: train loss 0.0129, val loss 9.1467\n",
      "iteration 19 / step 19: train loss 0.0114, val loss 9.1927\n"
     ]
    }
   ],
   "source": [
    "max_iters = 20\n",
    "eval_interval =20\n",
    "eval_iters = 10\n",
    "learning_rate = 1e-4\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "train_loader, val_loader = get_dataloaders(\n",
    "    train_data=train_data,\n",
    "    val_data=val_data,\n",
    "    block_size=block_size,\n",
    "    batch_size=batch_size,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for iteration in range(max_iters):\n",
    "    for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        # Evaluation\n",
    "        if batch_idx % eval_interval == 0 or batch_idx == len(train_loader) - 1:\n",
    "            losses = estimate_loss(\n",
    "                model=model,\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader,\n",
    "                eval_iters=min(eval_iters, len(val_loader))\n",
    "            )\n",
    "            train_losses.append(losses['train'])\n",
    "            val_losses.append(losses['val'])\n",
    "\n",
    "            print(\n",
    "                f\"iteration {iteration} / step {batch_idx}: \"\n",
    "                f\"train loss {losses['train']:.4f}, \"\n",
    "                f\"val loss {losses['val']:.4f}\"\n",
    "            )\n",
    "\n",
    "        # Training step\n",
    "        logits, loss = model(x_batch, y_batch)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Save checkpoint\n",
    "    save_checkpoint(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        epoch=iteration,\n",
    "        loss=loss.item(),\n",
    "        file_path=f\"../Data/pre_training/run_1/checkpoint_{iteration}.pth\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1168903e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label=\"Train Loss\", marker='o')\n",
    "plt.plot(val_losses, label=\"Validation Loss\", marker='o')\n",
    "plt.xlabel(\"Evaluation Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss Over Time\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13b4e1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pancakes:  on a hot pan, cook until crisp. Serve with chutney and sambar.\n",
      "  Parella and serve warm.\n",
      "  Scrambled Eggs: Whisk eggs with milk, cook sl\n"
     ]
    }
   ],
   "source": [
    "input_tokens = tokenizer.encode(\"Pancakes:  \")\n",
    "input_tokens = torch.tensor(\n",
    "    input_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model.generate(input_tokens=input_tokens, max_new_tokens=26)\n",
    "\n",
    "print(tokenizer.decode(output[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f609e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535bc55c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
