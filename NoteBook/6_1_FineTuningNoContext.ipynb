{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f118414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"../Data/recipes.json\"\n",
    "with open(file_path, \"r\",encoding='utf-8') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f401c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b6d17d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1a2fde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minbpe import RegexTokenizer\n",
    "\n",
    "tokenizer = RegexTokenizer()\n",
    "tokenizer.load(model_file=\"../Data/tokenizer/my_tokenizer.model\")\n",
    "\n",
    "\n",
    "def get_vocab_size(tokenizer: RegexTokenizer) -> int:\n",
    "    vocab = tokenizer.vocab\n",
    "    special_tokens = tokenizer.special_tokens\n",
    "\n",
    "    return len(vocab) + len(special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6efd5464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data = []\n",
    "for item in data:\n",
    "    tokenized_item = tokenizer.encode(item, allowed_special=\"all\")\n",
    "    tokenized_data.append(tokenized_item)\n",
    "\n",
    "len(tokenized_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e20410c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_split_index = int(0.9 * len(data))\n",
    "\n",
    "# # Adjusting the index to ensure that the training set ends with \"Assistant\" message\n",
    "# # and that the validation set starts with \"You\" message\n",
    "\n",
    "# # Scanning backward to find an Assistant message\n",
    "# split_index = initial_split_index\n",
    "# while split_index > 0 and not data[split_index-1].startswith('<|startoftext|>Assistant'):\n",
    "#     split_index -= 1\n",
    "\n",
    "# train_data = data[:split_index]\n",
    "# val_data = data[split_index:]\n",
    "\n",
    "# print(\"Training set: \")\n",
    "# print(f\"Start message: {train_data[0].split('<|separator|>')[0]}\")\n",
    "# print(f\"End message: {train_data[-1].split('<|separator|>')[0]}\")\n",
    "\n",
    "# print(\"\\nValidation set: \")\n",
    "# print(f\"Start message: {val_data[0].split('<|separator|>')[0]}\")\n",
    "# print(f\"End message: {val_data[-1].split('<|separator|>')[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25946876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Start message: <|startoftext|>Person 1\n",
      "End message: <|startoftext|>Person 2\n",
      "\n",
      "Validation set:\n",
      "Start message: <|startoftext|>Person 1\n",
      "End message: <|startoftext|>Person 2\n"
     ]
    }
   ],
   "source": [
    "initial_split_index = int(0.9 * len(data))\n",
    "\n",
    "split_index = initial_split_index\n",
    "while split_index > 0 and not data[split_index-1].startswith('<|startoftext|>Assistant'):\n",
    "    split_index -= 1\n",
    "\n",
    "# If no Assistant found, fallback to initial_split_index\n",
    "if split_index == 0:\n",
    "    split_index = initial_split_index\n",
    "\n",
    "train_data = data[:split_index]\n",
    "val_data = data[split_index:]\n",
    "\n",
    "print(\"Training set:\")\n",
    "if train_data:\n",
    "    print(f\"Start message: {train_data[0].split('<|separator|>')[0]}\")\n",
    "    print(f\"End message: {train_data[-1].split('<|separator|>')[0]}\")\n",
    "else:\n",
    "    print(\"⚠️ train_data is empty!\")\n",
    "\n",
    "print(\"\\nValidation set:\")\n",
    "if val_data:\n",
    "    print(f\"Start message: {val_data[0].split('<|separator|>')[0]}\")\n",
    "    print(f\"End message: {val_data[-1].split('<|separator|>')[0]}\")\n",
    "else:\n",
    "    print(\"⚠️ val_data is empty!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d929a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tokenized_data[:split_index]\n",
    "val_data = tokenized_data[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d407d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128\n",
    "\n",
    "\n",
    "def combine_turns(data: list[list[int]], should_trim_long_sequences: bool) -> list[list[int]]:\n",
    "    combined_turns_data = []\n",
    "    for i in range(0, len(data)-1, 2):\n",
    "        you_message = data[i]\n",
    "        assistant_message = data[i+1]\n",
    "        if not you_message or not assistant_message:\n",
    "            continue\n",
    "\n",
    "        final_message = you_message + assistant_message\n",
    "        if len(final_message) > block_size and should_trim_long_sequences:\n",
    "            final_message = final_message[-block_size:]\n",
    "\n",
    "        combined_turns_data.append(final_message)\n",
    "    return combined_turns_data\n",
    "\n",
    "\n",
    "combined_train_data = combine_turns(\n",
    "    data=train_data,\n",
    "    should_trim_long_sequences=True\n",
    ")\n",
    "combined_val_data = combine_turns(\n",
    "    data=val_data,\n",
    "    should_trim_long_sequences=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a8f1339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "Length before: 180\n",
      "Length after: 90\n",
      "\n",
      "Validation data\n",
      "Length before: 20\n",
      "Length after: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data\")\n",
    "print(f\"Length before: {len(train_data)}\")\n",
    "print(f\"Length after: {len(combined_train_data)}\")\n",
    "\n",
    "print(\"\\nValidation data\")\n",
    "print(f\"Length before: {len(val_data)}\")\n",
    "print(f\"Length after: {len(combined_val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c683683e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 91 at dim 1 (got 75)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_train_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m val_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(combined_val_data)\n",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 91 at dim 1 (got 75)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "train_data = torch.tensor(combined_train_data)\n",
    "val_data = torch.tensor(combined_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dde15c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([90, 128]), torch.Size([10, 128]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(3647)\n",
    "\n",
    "# The token `<|padding|>` is used to mask the padding tokens.\n",
    "# Masking means the model will ignore these tokens during training.\n",
    "# In other words, the loss will not be calculated for these tokens.\n",
    "padding_token = tokenizer.special_tokens[\"<|padding|>\"]\n",
    "\n",
    "\n",
    "def apply_padding_to_data(data: list[list[int]], block_size: int, padding_token: int) -> torch.Tensor:\n",
    "    tensors = []\n",
    "    for i in range(len(data)):\n",
    "        tensor = torch.tensor(data[i])\n",
    "        padded_tensor = torch.nn.functional.pad(\n",
    "            input=tensor,\n",
    "            # for right padding:\n",
    "            pad=(0, block_size - len(tensor)),\n",
    "            # pad=(block_size - len(tensor), 0),\n",
    "            value=padding_token\n",
    "        )\n",
    "        tensors.append(padded_tensor)\n",
    "\n",
    "    return torch.stack(tensors)\n",
    "\n",
    "\n",
    "train_data_tensor = apply_padding_to_data(\n",
    "    data=combined_train_data,\n",
    "    block_size=block_size,\n",
    "    padding_token=padding_token\n",
    ")\n",
    "val_data_tensor = apply_padding_to_data(\n",
    "    data=combined_val_data,\n",
    "    block_size=block_size,\n",
    "    padding_token=padding_token\n",
    ")\n",
    "\n",
    "train_data_tensor.shape, val_data_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9525b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1024,   80,  259,  115,  276,   32,   49, 1025,  963, 1026, 1024,   80,\n",
       "         259,  115,  276,   32,   50, 1025,  346,   32,  437,   44,  289,  297,\n",
       "         308,  339,  438,   44,  517,   44,   32,  258,  100,  285,  439,   46,\n",
       "          32,  466,  107,  320,   32,  322,   44,   32,  304,   44,   32,  258,\n",
       "         100,   32,  415,  116,  537,  525,   46,   32,  330,  107,   32,  276,\n",
       "          32,   97,   32,  468,  469,   32,  299,  289,  577,  399,  271,  704,\n",
       "         340,  109,   44,   32,  369,  578,   44,   32,  258,  100,  285,  474,\n",
       "          32,  268,  104,  285,  418,   46, 1026, 1028, 1028, 1028, 1028, 1028,\n",
       "        1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028,\n",
       "        1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028,\n",
       "        1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27a4fa09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1024,   80,  259,  115,  276,   32,   49, 1025,   77,  111,  106,  737,\n",
       "          32,   40,   77,  111,   99,  107,  839,  261,   41, 1026, 1024,   80,\n",
       "         259,  115,  276,   32,   50, 1025,   77,  617,  108,  101,   32,  868,\n",
       "         116,   32,  258,  100,   32,  620,  326,   44,   32,  312,  100,  285,\n",
       "         111,  100,   97,  785,   32,  258,  100,   32,  302,   46, 1026, 1028,\n",
       "        1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028,\n",
       "        1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028,\n",
       "        1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028,\n",
       "        1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028,\n",
       "        1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028,\n",
       "        1028, 1028, 1028, 1028, 1028, 1028, 1028, 1028])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "614ac273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([90, 128])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca1d0434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class FineTuningDataset(Dataset):\n",
    "    def __init__(self, data: torch.Tensor, device: torch.device, padding_token: int):\n",
    "        self.data = data  # shape: (num_samples, block_size)\n",
    "        self.device = device\n",
    "        self.padding_token = padding_token\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        sample = self.data[index]\n",
    "        x = sample.to(self.device)\n",
    "        y = sample[1:].to(self.device)\n",
    "        padding_tensor = torch.tensor([self.padding_token], device=self.device)\n",
    "        y = torch.cat((y, padding_tensor))\n",
    "        return x, y\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataset = FineTuningDataset(\n",
    "    data=train_data_tensor,\n",
    "    device=device,\n",
    "    padding_token=padding_token\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataset = FineTuningDataset(\n",
    "    data=val_data_tensor,\n",
    "    device=device,\n",
    "    padding_token=padding_token\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbab3b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 128]), torch.Size([64, 128]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40c12fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.342794 M parameters\n"
     ]
    }
   ],
   "source": [
    "from transformer.model import GPTLanguageModel\n",
    "\n",
    "block_size = 256\n",
    "n_embd = 512\n",
    "n_head = 4\n",
    "n_layer = 1\n",
    "dropout = 0.2\n",
    "batch_size = 64\n",
    "vocab_size = get_vocab_size(tokenizer)\n",
    "\n",
    "model = GPTLanguageModel(\n",
    "    vocab_size=vocab_size,\n",
    "    block_size=block_size,\n",
    "    n_embd=n_embd,\n",
    "    n_head=n_head,\n",
    "    n_layer=n_layer,\n",
    "    dropout=dropout,\n",
    "    device=device,\n",
    "    ignore_index=tokenizer.special_tokens[\"<|padding|>\"],\n",
    ").to(device)\n",
    "model = torch.compile(model)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "750962ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"../Data/pre_training/run_1/checkpoint_19.pth\"\n",
    "checkpoint = torch.load(checkpoint_path, weights_only=True)\n",
    "model_state_dict = checkpoint[\"model_state_dict\"]\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a033074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pancakes tional egg or tomato slices.\n",
      "  Shakshuka: Cook onion, garlic, and peppers. Add tomatoes and spices. Crack eggs into sauce, cover, and cook until set. Serve with bread.\n",
      "  Banana Smoothie: Blend banana, milk, honey, and ice until smooth. Serve chilled.\n",
      "  Oatmeal: Cook oats in milk/honey and top with fruits and nuts.\n",
      "  Breakfast Burrito: Scramble eggs with veggies, beans, and cheese. Roll inside a tortilla and serve warm.\n",
      "  S\n"
     ]
    }
   ],
   "source": [
    "input_tokens = tokenizer.encode(\"Pancakes \", allowed_special=\"all\")\n",
    "input_tokens = torch.tensor(\n",
    "    input_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model.generate(input_tokens=input_tokens, max_new_tokens=100)\n",
    "\n",
    "print(tokenizer.decode(output[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59d35fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(\n",
    "    model: torch.nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    ") -> Dict[str, float]:\n",
    "    output = {}\n",
    "    model.eval()\n",
    "\n",
    "    for split, loader in [('train', train_loader), ('val', val_loader)]:\n",
    "        losses = []\n",
    "        for x, y in loader:\n",
    "            with torch.no_grad():\n",
    "                _, loss = model(x, y)\n",
    "            losses.append(loss.item())\n",
    "        output[split] = sum(losses) / len(losses)\n",
    "\n",
    "    model.train()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23c8db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(\n",
    "    model: GPTLanguageModel,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epoch: int,\n",
    "    loss: float,\n",
    "    file_path: str = \"checkpoint.pth\"\n",
    ") -> None:\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "    }\n",
    "    torch.save(checkpoint, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d679ebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "# --- Disable Triton checks ---\n",
    "os.environ[\"TORCHINDUCTOR_DISABLE_TRITON\"] = \"1\"\n",
    "\n",
    "# --- Suppress TorchDynamo / Inductor warnings ---\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Optional: fully disable TorchDynamo verbose logging\n",
    "import torch._dynamo as dynamo\n",
    "dynamo.reset()\n",
    "dynamo.config.verbose = 0\n",
    "dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81f6feed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0903 20:56:39.176992 11052 site-packages\\torch\\_inductor\\utils.py:1250] [0/0] Not enough SMs to use max_autotune_gemm mode\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] WON'T CONVERT forward d:\\WORK space\\LLm\\NoteBook\\..\\transformer\\model.py line 129 \n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] due to: \n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Traceback (most recent call last):\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1213, in __call__\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     result = self._inner_convert(\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 598, in __call__\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile(\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1059, in _compile\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils_internal.py\", line 97, in wrapper_function\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return function(*args, **kwargs)\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 761, in compile_inner\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in _compile_inner\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     out_code = transform_code_object(code, transform)\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1422, in transform_code_object\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     transformations(instructions, code_options)\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 257, in _fn\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return fn(*args, **kwargs)\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in transform\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     tracer.run()\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3498, in run\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     super().run()\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1337, in run\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     while self.step():\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1246, in step\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3699, in RETURN_VALUE\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self._return(inst)\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3684, in _return\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.output.compile_subgraph(\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1179, in compile_subgraph\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.compile_and_call_fx_graph(\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1437, in compile_and_call_fx_graph\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1487, in call_user_compiler\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return self._call_user_compiler(gm)\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1519, in _call_user_compiler\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 150, in __call__\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py\", line 2347, in __call__\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 2100, in compile_fx\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3957, in create_backend\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise TritonMissing(inspect.currentframe())\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] torch._inductor.exc.TritonMissing: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Traceback (most recent call last):\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1213, in __call__\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     result = self._inner_convert(\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 598, in __call__\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile(\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1059, in _compile\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils_internal.py\", line 97, in wrapper_function\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return function(*args, **kwargs)\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 761, in compile_inner\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in _compile_inner\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     out_code = transform_code_object(code, transform)\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1422, in transform_code_object\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     transformations(instructions, code_options)\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 257, in _fn\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return fn(*args, **kwargs)\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in transform\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     tracer.run()\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3498, in run\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     super().run()\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1337, in run\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     while self.step():\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1246, in step\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3699, in RETURN_VALUE\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self._return(inst)\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3684, in _return\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.output.compile_subgraph(\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1179, in compile_subgraph\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.compile_and_call_fx_graph(\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1437, in compile_and_call_fx_graph\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1487, in call_user_compiler\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return self._call_user_compiler(gm)\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1519, in _call_user_compiler\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 150, in __call__\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py\", line 2347, in __call__\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 2100, in compile_fx\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3957, in create_backend\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise TritonMissing(inspect.currentframe())\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] torch._inductor.exc.TritonMissing: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "W0903 20:56:39.527943 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] WON'T CONVERT forward d:\\WORK space\\LLm\\NoteBook\\..\\transformer\\model.py line 86 \n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] due to: \n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Traceback (most recent call last):\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1213, in __call__\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     result = self._inner_convert(\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 598, in __call__\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile(\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1059, in _compile\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils_internal.py\", line 97, in wrapper_function\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return function(*args, **kwargs)\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 761, in compile_inner\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in _compile_inner\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     out_code = transform_code_object(code, transform)\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1422, in transform_code_object\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     transformations(instructions, code_options)\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 257, in _fn\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return fn(*args, **kwargs)\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in transform\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     tracer.run()\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3498, in run\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     super().run()\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1337, in run\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     while self.step():\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1246, in step\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3699, in RETURN_VALUE\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self._return(inst)\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3684, in _return\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.output.compile_subgraph(\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1144, in compile_subgraph\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.compile_and_call_fx_graph(\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1437, in compile_and_call_fx_graph\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1487, in call_user_compiler\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return self._call_user_compiler(gm)\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1519, in _call_user_compiler\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 150, in __call__\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py\", line 2347, in __call__\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 2100, in compile_fx\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3957, in create_backend\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise TritonMissing(inspect.currentframe())\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] torch._inductor.exc.TritonMissing: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Traceback (most recent call last):\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1213, in __call__\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     result = self._inner_convert(\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 598, in __call__\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile(\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1059, in _compile\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils_internal.py\", line 97, in wrapper_function\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return function(*args, **kwargs)\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 761, in compile_inner\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in _compile_inner\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     out_code = transform_code_object(code, transform)\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1422, in transform_code_object\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     transformations(instructions, code_options)\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 257, in _fn\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return fn(*args, **kwargs)\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in transform\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     tracer.run()\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3498, in run\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     super().run()\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1337, in run\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     while self.step():\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1246, in step\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3699, in RETURN_VALUE\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self._return(inst)\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3684, in _return\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.output.compile_subgraph(\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1144, in compile_subgraph\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.compile_and_call_fx_graph(\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1437, in compile_and_call_fx_graph\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1487, in call_user_compiler\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return self._call_user_compiler(gm)\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1519, in _call_user_compiler\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 150, in __call__\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py\", line 2347, in __call__\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 2100, in compile_fx\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3957, in create_backend\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise TritonMissing(inspect.currentframe())\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] torch._inductor.exc.TritonMissing: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "W0903 20:56:41.176971 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] WON'T CONVERT forward d:\\WORK space\\LLm\\NoteBook\\..\\transformer\\model.py line 45 \n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] due to: \n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Traceback (most recent call last):\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1213, in __call__\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     result = self._inner_convert(\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 598, in __call__\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile(\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1059, in _compile\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils_internal.py\", line 97, in wrapper_function\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return function(*args, **kwargs)\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 761, in compile_inner\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in _compile_inner\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     out_code = transform_code_object(code, transform)\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1422, in transform_code_object\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     transformations(instructions, code_options)\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 257, in _fn\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return fn(*args, **kwargs)\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in transform\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     tracer.run()\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3498, in run\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     super().run()\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1337, in run\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     while self.step():\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1246, in step\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3699, in RETURN_VALUE\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self._return(inst)\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3684, in _return\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.output.compile_subgraph(\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1144, in compile_subgraph\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.compile_and_call_fx_graph(\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1437, in compile_and_call_fx_graph\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1487, in call_user_compiler\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return self._call_user_compiler(gm)\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1519, in _call_user_compiler\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 150, in __call__\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py\", line 2347, in __call__\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 2100, in compile_fx\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3957, in create_backend\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise TritonMissing(inspect.currentframe())\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] torch._inductor.exc.TritonMissing: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Traceback (most recent call last):\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1213, in __call__\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     result = self._inner_convert(\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 598, in __call__\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile(\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1059, in _compile\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils_internal.py\", line 97, in wrapper_function\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return function(*args, **kwargs)\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 761, in compile_inner\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in _compile_inner\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     out_code = transform_code_object(code, transform)\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1422, in transform_code_object\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     transformations(instructions, code_options)\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 257, in _fn\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return fn(*args, **kwargs)\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in transform\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     tracer.run()\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3498, in run\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     super().run()\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1337, in run\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     while self.step():\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1246, in step\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3699, in RETURN_VALUE\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self._return(inst)\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3684, in _return\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.output.compile_subgraph(\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1144, in compile_subgraph\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.compile_and_call_fx_graph(\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1437, in compile_and_call_fx_graph\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1487, in call_user_compiler\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return self._call_user_compiler(gm)\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1519, in _call_user_compiler\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 150, in __call__\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py\", line 2347, in __call__\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 2100, in compile_fx\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3957, in create_backend\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise TritonMissing(inspect.currentframe())\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] torch._inductor.exc.TritonMissing: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "W0903 20:56:42.547281 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] WON'T CONVERT forward d:\\WORK space\\LLm\\NoteBook\\..\\transformer\\model.py line 20 \n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] due to: \n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Traceback (most recent call last):\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1213, in __call__\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     result = self._inner_convert(\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 598, in __call__\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile(\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1059, in _compile\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils_internal.py\", line 97, in wrapper_function\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return function(*args, **kwargs)\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 761, in compile_inner\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in _compile_inner\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     out_code = transform_code_object(code, transform)\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1422, in transform_code_object\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     transformations(instructions, code_options)\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 257, in _fn\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return fn(*args, **kwargs)\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in transform\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     tracer.run()\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3498, in run\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     super().run()\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1337, in run\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     while self.step():\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1246, in step\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3699, in RETURN_VALUE\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self._return(inst)\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3684, in _return\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.output.compile_subgraph(\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1144, in compile_subgraph\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.compile_and_call_fx_graph(\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1437, in compile_and_call_fx_graph\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1487, in call_user_compiler\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return self._call_user_compiler(gm)\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1519, in _call_user_compiler\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 150, in __call__\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py\", line 2347, in __call__\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 2100, in compile_fx\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3957, in create_backend\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise TritonMissing(inspect.currentframe())\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] torch._inductor.exc.TritonMissing: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Traceback (most recent call last):\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1213, in __call__\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     result = self._inner_convert(\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 598, in __call__\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile(\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1059, in _compile\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils_internal.py\", line 97, in wrapper_function\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return function(*args, **kwargs)\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 761, in compile_inner\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in _compile_inner\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     out_code = transform_code_object(code, transform)\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1422, in transform_code_object\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     transformations(instructions, code_options)\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 257, in _fn\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return fn(*args, **kwargs)\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in transform\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     tracer.run()\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3498, in run\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     super().run()\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1337, in run\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     while self.step():\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1246, in step\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3699, in RETURN_VALUE\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self._return(inst)\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3684, in _return\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.output.compile_subgraph(\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1144, in compile_subgraph\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.compile_and_call_fx_graph(\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1437, in compile_and_call_fx_graph\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1487, in call_user_compiler\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return self._call_user_compiler(gm)\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1519, in _call_user_compiler\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 150, in __call__\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py\", line 2347, in __call__\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 2100, in compile_fx\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3957, in create_backend\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise TritonMissing(inspect.currentframe())\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] torch._inductor.exc.TritonMissing: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "W0903 20:56:43.003618 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] WON'T CONVERT forward d:\\WORK space\\LLm\\NoteBook\\..\\transformer\\model.py line 63 \n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] due to: \n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Traceback (most recent call last):\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1213, in __call__\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     result = self._inner_convert(\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 598, in __call__\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile(\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1059, in _compile\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils_internal.py\", line 97, in wrapper_function\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return function(*args, **kwargs)\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 761, in compile_inner\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in _compile_inner\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     out_code = transform_code_object(code, transform)\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1422, in transform_code_object\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     transformations(instructions, code_options)\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 257, in _fn\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return fn(*args, **kwargs)\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in transform\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     tracer.run()\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3498, in run\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     super().run()\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1337, in run\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     while self.step():\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1246, in step\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3699, in RETURN_VALUE\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self._return(inst)\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3684, in _return\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.output.compile_subgraph(\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1144, in compile_subgraph\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.compile_and_call_fx_graph(\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1437, in compile_and_call_fx_graph\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1487, in call_user_compiler\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return self._call_user_compiler(gm)\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1519, in _call_user_compiler\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 150, in __call__\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py\", line 2347, in __call__\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 2100, in compile_fx\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3957, in create_backend\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise TritonMissing(inspect.currentframe())\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] torch._inductor.exc.TritonMissing: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Traceback (most recent call last):\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1213, in __call__\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     result = self._inner_convert(\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 598, in __call__\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile(\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1059, in _compile\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils_internal.py\", line 97, in wrapper_function\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return function(*args, **kwargs)\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 761, in compile_inner\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 797, in _compile_inner\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     out_code = transform_code_object(code, transform)\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1422, in transform_code_object\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     transformations(instructions, code_options)\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 257, in _fn\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return fn(*args, **kwargs)\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in transform\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     tracer.run()\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3498, in run\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     super().run()\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1337, in run\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     while self.step():\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1246, in step\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3699, in RETURN_VALUE\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self._return(inst)\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3684, in _return\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.output.compile_subgraph(\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1144, in compile_subgraph\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     self.compile_and_call_fx_graph(\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1437, in compile_and_call_fx_graph\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1487, in call_user_compiler\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return self._call_user_compiler(gm)\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1519, in _call_user_compiler\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 150, in __call__\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py\", line 2347, in __call__\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 2100, in compile_fx\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]   File \"c:\\Users\\Altai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3957, in create_backend\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280]     raise TritonMissing(inspect.currentframe())\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] torch._inductor.exc.TritonMissing: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "W0903 20:56:43.235271 11052 site-packages\\torch\\_dynamo\\convert_frame.py:1280] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / step 0: train loss 7.7414, val loss 8.0894\n",
      "iteration 0 / step 1: train loss 6.8644, val loss 7.2008\n",
      "iteration 1 / step 0: train loss 6.0779, val loss 6.4758\n",
      "iteration 1 / step 1: train loss 5.7945, val loss 6.2073\n",
      "iteration 2 / step 0: train loss 5.5618, val loss 6.0289\n",
      "iteration 2 / step 1: train loss 5.2637, val loss 5.6862\n",
      "iteration 3 / step 0: train loss 4.9428, val loss 5.3299\n",
      "iteration 3 / step 1: train loss 4.7624, val loss 5.0804\n",
      "iteration 4 / step 0: train loss 4.5898, val loss 4.9262\n",
      "iteration 4 / step 1: train loss 4.4659, val loss 4.8086\n"
     ]
    }
   ],
   "source": [
    "max_iters = 5\n",
    "eval_interval = 3\n",
    "learning_rate = 6e-5\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for iteration in range(max_iters):\n",
    "    for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        # Evaluation\n",
    "        if batch_idx % eval_interval == 0 or batch_idx == len(train_loader) - 1:\n",
    "            losses = estimate_loss(\n",
    "                model=model,\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader,\n",
    "            )\n",
    "            train_losses.append(losses['train'])\n",
    "            val_losses.append(losses['val'])\n",
    "\n",
    "            print(\n",
    "                f\"iteration {iteration} / step {batch_idx}: \"\n",
    "                f\"train loss {losses['train']:.4f}, \"\n",
    "                f\"val loss {losses['val']:.4f}\"\n",
    "            )\n",
    "\n",
    "        # Training step\n",
    "        logits, loss = model(x_batch, y_batch)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Save checkpoint\n",
    "    save_checkpoint(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        epoch=iteration,\n",
    "        loss=loss.item(),\n",
    "        file_path=f\"../Data/fine_tuning/run_3/checkpoint_{iteration}.pth\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56d4b8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Evaluation Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss Over Time\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c9c7eb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid token id: 1032",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     20\u001b[0m input_tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((input_tokens, output_tokens[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:]), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m model_answer \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlast_generated_token\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output_tokens[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m>\u001b[39m block_size:\n\u001b[0;32m     24\u001b[0m     input_tokens \u001b[38;5;241m=\u001b[39m input_tokens[:, \u001b[38;5;241m-\u001b[39mblock_size:]\n",
      "File \u001b[1;32md:\\WORK space\\LLm\\NoteBook\\..\\minbpe\\regex.py:90\u001b[0m, in \u001b[0;36mRegexTokenizer.decode\u001b[1;34m(self, ids)\u001b[0m\n\u001b[0;32m     87\u001b[0m         part_bytes\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minverse_special_tokens[idx]\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 90\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid token id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m text_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(part_bytes)\n\u001b[0;32m     92\u001b[0m text \u001b[38;5;241m=\u001b[39m text_bytes\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid token id: 1032"
     ]
    }
   ],
   "source": [
    "def get_input_tokens(message: str) -> torch.Tensor:\n",
    "    input_tokens = tokenizer.encode(\n",
    "        f\"<|startoftext|>{message}<|separator|>\", allowed_special=\"all\")\n",
    "    input_tokens = torch.tensor(\n",
    "        input_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "    return input_tokens\n",
    "\n",
    "\n",
    "user_message = \"Pancakes\"\n",
    "input_tokens = get_input_tokens(message=user_message)\n",
    "model_answer = \"\"\n",
    "\n",
    "model.eval()\n",
    "while True:\n",
    "    output_tokens = model.generate(input_tokens=input_tokens, max_new_tokens=1)\n",
    "    last_generated_token = output_tokens[0, -1].item()\n",
    "    if last_generated_token == tokenizer.special_tokens[\"<|endoftext|>\"]:\n",
    "        break\n",
    "\n",
    "    input_tokens = torch.cat((input_tokens, output_tokens[:, -1:]), dim=1)\n",
    "    model_answer += tokenizer.decode([last_generated_token])\n",
    "\n",
    "    if len(output_tokens[0]) > block_size:\n",
    "        input_tokens = input_tokens[:, -block_size:]\n",
    "\n",
    "print(f\"You: {user_message}\")\n",
    "print(f\"Assistant: {model_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016db94c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
